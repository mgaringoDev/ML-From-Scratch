{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the database from a list of characters that is found in the input.txt\n",
    "# should be simple plain text file\n",
    "data = open('input.txt', 'r').read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of characters by first identifying the set() of characters and place them in a list()\n",
    "# NOTE: set() function here creates an unorders collection with no duplicate elements\n",
    "chars = list(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the size of the data and the size of the vocabulary we have\n",
    "data_size, vocab_size = len(data), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate the characters and give indices to them\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "concatHiddenLayerInputLayerSize = vocab_size + hidden_size\n",
    "\n",
    "Wih=np.random.randn(concatHiddenLayerInputLayerSize, hidden_size) \n",
    "Wfh=np.random.randn(concatHiddenLayerInputLayerSize, hidden_size) \n",
    "Woh=np.random.randn(concatHiddenLayerInputLayerSize, hidden_size) \n",
    "Wgh=np.random.randn(concatHiddenLayerInputLayerSize, hidden_size) \n",
    "Wch=np.random.randn(concatHiddenLayerInputLayerSize, hidden_size) \n",
    "Wyh=np.random.randn(hidden_size, vocab_size) \n",
    "\n",
    "bi=np.zeros((1, hidden_size))\n",
    "bf=np.zeros((1, hidden_size))\n",
    "bo=np.zeros((1, hidden_size))\n",
    "bg=np.zeros((1, hidden_size))\n",
    "bc=np.zeros((1, hidden_size))\n",
    "by=np.zeros((1, hidden_size))\n",
    "\n",
    "\n",
    "# Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "# Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "# Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "# bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "# by = np.zeros((vocab_size, 1)) # output bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    sigmoidOut = 1 / (1 + np.exp(-x))    \n",
    "    return sigmoidOut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigmoid(x):\n",
    "    dsigmoidOut = sigmoid(x)*(1 - sigmoid(x))\n",
    "    return dsigmoidOut  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    tanhOut = np.tanh(x)\n",
    "    return tanhOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtanh(x):\n",
    "    dtanh = 1 - tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the data index as well as the iteration \n",
    "# n = interation counter\n",
    "# p = data pointer\n",
    "n, p = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the weights all to zero\n",
    "mWih = np.zeros_like(Wih)\n",
    "mWfh = np.zeros_like(Wfh)\n",
    "mWoh = np.zeros_like(Woh)\n",
    "mWgh = np.zeros_like(Wgh)\n",
    "mWch = np.zeros_like(Wch)\n",
    "mWyh = np.zeros_like(Wyh)\n",
    "\n",
    "# Bias\n",
    "mbi = np.zeros_like(bi)\n",
    "mbf = np.zeros_like(bf)\n",
    "mbo = np.zeros_like(bo)\n",
    "mbg = np.zeros_like(bg)\n",
    "mbc = np.zeros_like(bc)\n",
    "mby = np.zeros_like(by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1 Truncated Backprop through time paradigm\n",
    "# prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "# Because we are doing truncated backprop thorugh time (by 25 steps) we need to see if we get an overflow.  If so then we need\n",
    "# to initialize everything back to zero.  this means that the previous hidden state is now 0 and the data pointer is also back\n",
    "# to zero\n",
    "if p+seq_length+1 >= len(data) or n == 0: \n",
    "    # reset RNN memory\n",
    "    hprev = np.zeros((1,hidden_size))\n",
    "    cprev = np.zeros((1,hidden_size))\n",
    "    # go from start of data\n",
    "    p = 0 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #2 - Obtain Inputs\n",
    "# Get the sequence of inputs in the database with length seq_length\n",
    "# input is a list of indicies in the char_to_ix\n",
    "inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #3 - Obtain Outputs\n",
    "# Get the sequence of outputs in the database with length seq_length\n",
    "# basically the next character of the input\n",
    "targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inits for forward pass\n",
    "# xs: input state\n",
    "# hs: hidden state\n",
    "# ys: output state\n",
    "# ps: propbability state\n",
    "xs, hs, cs, ys, ps = {}, {}, {}, {},{}\n",
    "hs[-1] = np.copy(hprev)\n",
    "cs[-1] = np.copy(cprev)\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoder\n",
    "# get zeros\n",
    "xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "# place a one where the input index is\n",
    "xs[t][inputs[t]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = np.concatenate((hprev[0],np.ravel(xs[t])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = sigmoid(np.dot(xc,Wih) + bi)\n",
    "ft = sigmoid(np.dot(xc,Wfh) + bf)\n",
    "ot = sigmoid(np.dot(xc,Woh) + bo)\n",
    "gt = tanh(np.dot(xc,Wgh) + bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ft.T*cprev + it *gt\n",
    "ht = ot * tanh(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 100L)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1L, 100L)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 100L)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
