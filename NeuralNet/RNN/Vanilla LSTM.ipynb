{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the following resources:\n",
    "- Background\n",
    "    - [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "    - [Deriving LSTM Gradient for Backpropagation](https://wiseodd.github.io/techblog/2016/08/12/lstm-backprop/)\n",
    "    - [hackernoon: Understanding architecture of LSTM cell from scratch with code.](https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4)\n",
    "    - [Backpropogating an LSTM: A Numerical Example](https://medium.com/@aidangomez/let-s-do-this-f9b699de31d9)\n",
    "    - [Learning Graph-Level Representations with Recurrent Neural Networks](https://arxiv.org/pdf/1805.07683.pdf)\n",
    "    - [Simple LSTM](http://nicodjimenez.github.io/2014/08/08/lstm.html)\n",
    "    - [Simple LSTM Code](https://github.com/nicodjimenez/lstm/blob/master/lstm.py)\n",
    "- Standford\n",
    "    - [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "    - [Karpathy Git Repo LSTM](https://gist.github.com/karpathy/587454dc0146a6ae21fc)\n",
    "    - [Vector,Matrix and Tensor Derivatives Cheatsheet](http://cs231n.stanford.edu/vecDerivs.pdf)\n",
    "- Vanilla\n",
    "    - [Vanilla Recurrent Neural Networks](https://hacktilldawn.com/2017/03/26/vanilla-recurrent-neural-networks/)\n",
    "    - [Vanilla LSTM with numpy](http://blog.varunajayasiri.com/numpy_lstm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data to be learnt from is in the same directory as this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('input.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data and calculate indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 2421 characters, 42 unique\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "data_size, X_size = len(data), len(chars)\n",
    "print(\"data has %d characters, %d unique\" % (data_size, X_size))\n",
    "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
    "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_size = 100 # Size of the hidden layer\n",
    "T_steps = 25 # Number of time steps (length of the sequence) used for training\n",
    "learning_rate = 1e-1 # Learning rate\n",
    "z_size = H_size + X_size # Size of concatenate(H, X) vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-8 # adagrad initialization note that this is usually between 1e-4 and 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential average of loss\n",
    "# Initialize to a error of a random model\n",
    "smooth_loss = -np.log(1.0 / X_size) * T_steps\n",
    "\n",
    "iteration, pointer = 0, 0\n",
    "\n",
    "# For the graph\n",
    "plot_iter = np.zeros((0))\n",
    "plot_loss = np.zeros((0))\n",
    "\n",
    "# Number of characters for the model to generate\n",
    "numOfCharToGenerate = 100\n",
    "\n",
    "# Number of iteration before showing the progress of the model\n",
    "numOfIterToShowProgress = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value #parameter value\n",
    "        self.d = np.zeros_like(value) #derivative\n",
    "        self.m = np.zeros_like(value) #momentum for AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are initializing using the [Xavier initalization method](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf?hc_location=ufi). Which says that we multiply a random distribution with either\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(W) = \\frac{1}{n_\\text{in}}\\\\\n",
    "\\text{Var}(W) = \\frac{2}{n_\\text{in} + n_\\text{out}}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "In short, it helps signals reach deep into the network.\n",
    "\n",
    "- If the weights in a network start too small, then the signal shrinks as it passes through each layer until it’s too tiny to be useful.\n",
    "- If the weights in a network start too large, then the signal grows as it passes through each layer until it’s too massive to be useful.\n",
    "\n",
    "Xavier initialization makes sure the weights are ‘just right’, keeping the signal in a reasonable range of values through many layers. To go any further than this, you’re going to need a small amount of statistics - specifically you need to know about random distributions and their variance.\n",
    "\n",
    "For a detailed explanation refer to this [blog](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization) if the paper is too convoluted. We use the second implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        # forget gate: wheter to erase the cell or not\n",
    "        self.W_f = Param('W_f', \n",
    "                         np.random.randn(H_size, z_size) * np.sqrt(2.0/(H_size+z_size)))\n",
    "        self.b_f = Param('b_f',\n",
    "                         np.zeros((H_size, 1)))\n",
    "        \n",
    "        # input gate: whether to wrote to the cell or not\n",
    "        self.W_i = Param('W_i',\n",
    "                         np.random.randn(H_size, z_size) * np.sqrt(2.0/(H_size+z_size)))\n",
    "        self.b_i = Param('b_i',\n",
    "                         np.zeros((H_size, 1)))\n",
    "        \n",
    "         # gate gate?? How much do we write to the cell\n",
    "        self.W_g = Param('W_g',\n",
    "                         np.random.randn(H_size, z_size) * np.sqrt(2.0/(H_size+z_size)))\n",
    "        self.b_g = Param('b_g',\n",
    "                         np.zeros((H_size, 1)))\n",
    "        \n",
    "         # output gate: How much to reveal to the cell\n",
    "        self.W_o = Param('W_o',\n",
    "                         np.random.randn(H_size, z_size) * np.sqrt(2.0/(H_size+z_size)))\n",
    "        self.b_o = Param('b_o',\n",
    "                         np.zeros((H_size, 1)))\n",
    "\n",
    "        #For final layer to predict the next character\n",
    "        self.W_v = Param('W_v',\n",
    "                         np.random.randn(X_size, H_size) * np.sqrt(2.0/(X_size+H_size)))\n",
    "        self.b_v = Param('b_v',\n",
    "                         np.zeros((X_size, 1)))\n",
    "        \n",
    "    # this method makes it easier to loop through each paramters for either updating or clearing them out for initialization.    \n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_g, self.W_o, self.W_v,\n",
    "               self.b_f, self.b_i, self.b_g, self.b_o, self.b_v]\n",
    "        \n",
    "parameters = Parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions and Derivatives\n",
    "\n",
    "### Sigmoid\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma(x) &= \\frac{1}{1 + e^{-x}}\\\\\n",
    "\\frac{d\\sigma(x)}{dx} &= \\sigma(x) \\cdot (1 - \\sigma(x))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{d\\text{tanh}(x)}{dx} &= 1 - \\text{tanh}^2(x)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass\n",
    "\n",
    "![LSTM](https://i.imgur.com/CP4l3WK.png)\n",
    "\n",
    "*Operation $z$ is the concatenation of $x$ and $h_{t-1}$*\n",
    "\n",
    "### Calculations\n",
    "#### Concatenation of hprev and xt\n",
    "\\begin{align}\n",
    "z & = [h_{t-1}, x_t] \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### LSTM functions\n",
    "\\begin{align}\n",
    "f_t & = \\sigma(W_f \\cdot z + b_f) \\\\\n",
    "i_t & = \\sigma(W_i \\cdot z + b_i) \\\\\n",
    "g_t & = tanh(W_C \\cdot z + b_C) \\\\\n",
    "C_t & = f_t * C_{t-1} + i_t * g_t \\\\\n",
    "o_t & = \\sigma(W_o \\cdot z + b_t) \\\\\n",
    "h_t &= o_t * tanh(C_t) \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Logits\n",
    "\\begin{align}\n",
    "v_t &= W_v \\cdot h_t + b_v \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Softmax\n",
    "\\begin{align}\n",
    "\\hat{y_t} &= \\text{softmax}(v_t)\n",
    "\\end{align}\n",
    "\n",
    "$\\hat{y_t}$ is `y` in code and $y_t$ is `targets`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just go through the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_prev, C_prev, p = parameters):\n",
    "    assert x.shape == (X_size, 1)\n",
    "    assert h_prev.shape == (H_size, 1)\n",
    "    assert C_prev.shape == (H_size, 1)\n",
    "    \n",
    "    # concatontae hiddenstate matrix with the input matrix to make calculatations cleaner\n",
    "    z = np.row_stack((h_prev, x))\n",
    "    \n",
    "    # calculate LSTM gates \n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    g = tanh(np.dot(p.W_g.v, z) + p.b_g.v)\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    \n",
    "    # cstate and hidden state for this tick\n",
    "    C = f * C_prev + i * g    \n",
    "    h = o * tanh(C)\n",
    "    \n",
    "    # softmax loss\n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "    return z, f, i, g, C, o, h, v, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass\n",
    "\n",
    "#### Loss\n",
    "\n",
    "\\begin{align}\n",
    "L_k &= -\\sum_{t=k}^T\\sum_j y_{t,j} log \\hat{y_{t,j}} \\\\\n",
    "L &= L_1 \\\\\n",
    "\\end{align}\n",
    "\n",
    "#### Gradients\n",
    "\n",
    "\\begin{align}\n",
    "dv_t &= \\hat{y_t} - y_t \\\\\n",
    "dh_t &= dh'_t + W_y^T \\cdot dv_t \\\\\n",
    "do_t &= dh_t * \\text{tanh}(C_t) \\\\\n",
    "dC_t &= dC'_t + dh_t * o_t * (1 - \\text{tanh}^2(C_t))\\\\\n",
    "dg_t &= dC_t * i_t \\\\\n",
    "di_t &= dC_t * g_t \\\\\n",
    "df_t &= dC_t * C_{t-1} \\\\\n",
    "\\\\\n",
    "df'_t &= f_t * (1 - f_t) * df_t \\\\\n",
    "di'_t &= i_t * (1 - i_t) * di_t \\\\\n",
    "dg'_{t-1} &= (1 - g_t^2) * dg_t \\\\\n",
    "do'_t &= o_t * (1 - o_t) * do_t \\\\\n",
    "dz_t &= W_f^T \\cdot df'_t \\\\\n",
    "     &+ W_i^T \\cdot di_t \\\\\n",
    "     &+ W_C^T \\cdot dg_t \\\\\n",
    "     &+ W_o^T \\cdot do_t \\\\\n",
    "\\\\\n",
    "[dh'_{t-1}, dx_t] &= dz_t \\\\\n",
    "dC'_t &= f_t * dC_t\n",
    "\\end{align}\n",
    "\n",
    "* $dC'_t = \\frac{\\partial L_{t+1}}{\\partial C_t}$ and $dh'_t = \\frac{\\partial L_{t+1}}{\\partial h_t}$\n",
    "* $dC_t = \\frac{\\partial L}{\\partial C_t} = \\frac{\\partial L_t}{\\partial C_t}$ and $dh_t = \\frac{\\partial L}{\\partial h_t} = \\frac{\\partial L_{t}}{\\partial h_t}$\n",
    "* All other derivatives are of $L$\n",
    "* `target` is target character index $y_t$\n",
    "* `dh_next` is $dh'_{t}$ (size H x 1)\n",
    "* `dC_next` is $dC'_{t}$ (size H x 1)\n",
    "* `C_prev` is $C_{t-1}$ (size H x 1)\n",
    "* $df'_t$, $di'_t$, $dg'_t$, and $do'_t$ are *also* assigned to `df`, `di`, `dC_bar`, and `do` in the **code**.\n",
    "* *Returns* $dh_t$ and $dC_t$\n",
    "\n",
    "#### Model parameter gradients\n",
    "\n",
    "\\begin{align}\n",
    "dW_v &= dv_t \\cdot h_t^T \\\\\n",
    "db_v &= dv_t \\\\\n",
    "\\\\\n",
    "dW_f &= df'_t \\cdot z^T \\\\\n",
    "db_f &= df'_t \\\\\n",
    "\\\\\n",
    "dW_i &= di'_t \\cdot z^T \\\\\n",
    "db_i &= di'_t \\\\\n",
    "\\\\\n",
    "dW_C &= dg'_t \\cdot z^T \\\\\n",
    "db_C &= dg'_t \\\\\n",
    "\\\\\n",
    "dW_o &= do'_t \\cdot z^T \\\\\n",
    "db_o &= do'_t \\\\\n",
    "\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward()\n",
    "\n",
    "Note: When traversing through the computational network to get the local gradient of a node it is [**upstream**] * [**downstream**]\n",
    "\n",
    "- **add gate:** gradient distributer ... pass the exact same value through each of the branches\n",
    "- **max gate:** gradient router ... passes the entire upstream gradient to the branch with the highest upstream value\n",
    "- **mul gate:** gradient switcher ... local gradient is the value of the other branch (think of this a s ad/dx of a linear function)\n",
    "- **functional gate:** gradient of the function ... take the derivative of this function with respect to the upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(target, dh_next, dC_next, C_prev,\n",
    "             z, f, i, g, C, o, h, v, y,\n",
    "             p = parameters):\n",
    "    \n",
    "    assert z.shape == (X_size + H_size, 1)\n",
    "    assert v.shape == (X_size, 1)\n",
    "    assert y.shape == (X_size, 1)\n",
    "    \n",
    "    for param in [dh_next, dC_next, C_prev, f, i, g, C, o, h]:\n",
    "        assert param.shape == (H_size, 1)\n",
    "    \n",
    "    # Loss function\n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "    \n",
    "    # Loss function wrt logit\n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "    \n",
    "    # logit wrt hidden state\n",
    "    # NOTE: from here on dh is common in the calculations for all the weights\n",
    "    dh = np.dot(p.W_v.v.T, dv)        \n",
    "    dh += dh_next\n",
    "    \n",
    "    # calculate the affects of the ---------------------- Woh gate    \n",
    "    # backprop through the mul gate\n",
    "    do = dh * tanh(C)\n",
    "    # backprop through the sigmoide gate\n",
    "    do = dsigmoid(o) * do\n",
    "    # backprop through the final mul gate  \n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "\n",
    "    # calculate the affects of the ---------------------- Wgh gate    \n",
    "    dC = np.copy(dC_next)\n",
    "    # backprop through the mul gate and then the tanh gate \n",
    "    # NOTE: you are adding dC or in this case because we copied dC_next it is technically dC_next.  This addition is because \n",
    "    # there are multiple branches and in this case you simply add the two incoming gradients    \n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    # backprop through the mul gate \n",
    "    dg = dC * i\n",
    "    # backprop through the tanh gate\n",
    "    dg = dtanh(g) * dg\n",
    "    # backprop through the final mul gate\n",
    "    p.W_g.d += np.dot(dg, z.T)\n",
    "    p.b_g.d += dg\n",
    "\n",
    "    # calculate the affects of the ---------------------- Wih gate    \n",
    "    # NOTE: i and g have many things in common because they followin the same path through the computational graph so let \n",
    "    # us that redunancy and just start where it and gt are going through the mul gate\n",
    "    # pass through the mul gate    \n",
    "    di = dC * g\n",
    "    # backprop through the sigmoid gate\n",
    "    di = dsigmoid(i) * di\n",
    "    # backprop through the final mul gate\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "\n",
    "    # calculate the affects of the ---------------------- Wfh gate    \n",
    "    # NOTE: similar to i and g f also have many things in common because they followin the same path through the \n",
    "    # computational graph so let use that redunancy and just start where it and gt are going through the mul gate\n",
    "    # backprop through the mul gate    \n",
    "    df = dC * C_prev\n",
    "    # backprop through the sigmoid gate\n",
    "    df = dsigmoid(f) * df\n",
    "    # backprop through the final mul gate\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "\n",
    "    # calculate the affects of the ---------------------- z weigths\n",
    "    dz = (np.dot(p.W_f.v.T, df)\n",
    "         + np.dot(p.W_i.v.T, di)\n",
    "         + np.dot(p.W_g.v.T, dg)\n",
    "         + np.dot(p.W_o.v.T, do))\n",
    "    \n",
    "    # only take the portion of the input that is affected by the hidden states.  Recall that z is a concatination of the\n",
    "    # hidden state and the input one hot vector\n",
    "    dh_prev = dz[:H_size, :]\n",
    "    \n",
    "    # calculate the affects of the ---------------------- c weights\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear gradients \n",
    "Used for initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gradients(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip gradients \n",
    "This is to mitigate exploding gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradients(params = parameters):\n",
    "    # clip the crapids to [-1,1]\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -5, 5, out=p.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
    "\n",
    "* `input`, `target` are list of integers, with character indexes.\n",
    "* `h_prev` is the array of initial `h` at $h_{-1}$ (size H x 1)\n",
    "* `C_prev` is the array of initial `C` at $C_{-1}$ (size H x 1)\n",
    "* *Returns* loss, final $h_T$ and $C_T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward-Backward\n",
    "\n",
    "Perform forward and then back prop in one function to keep things nice and tidy when reading the main LSTM loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    global paramters\n",
    "    \n",
    "    # To store the values for each time step\n",
    "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "    g_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s =  {}, {}\n",
    "    \n",
    "    # Values at t - 1\n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    \n",
    "    loss = 0\n",
    "    # Loop through time steps\n",
    "    assert len(inputs) == T_steps\n",
    "    for t in range(len(inputs)):\n",
    "        \n",
    "        # one hot encode the input vector\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1 # Input character\n",
    "        \n",
    "        # Forward pass\n",
    "        (z_s[t], f_s[t], i_s[t],\n",
    "        g_s[t], C_s[t], o_s[t], h_s[t],\n",
    "        v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) \n",
    "        \n",
    "        # Loss for this tick\n",
    "        loss += -np.log(y_s[t][targets[t], 0]) \n",
    "    \n",
    "    # clear the gradients for the next step size\n",
    "    clear_gradients()\n",
    "    \n",
    "    #dh from the next character\n",
    "    dh_next = np.zeros_like(h_s[0]) \n",
    "    #dh from the next character\n",
    "    dC_next = np.zeros_like(C_s[0]) \n",
    "\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # Backward pass\n",
    "        dh_next, dC_next = \\\n",
    "            backward(target = targets[t], dh_next = dh_next,\n",
    "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                     z = z_s[t], f = f_s[t], i = i_s[t], g = g_s[t],\n",
    "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                     y = y_s[t])\n",
    "    \n",
    "    # clip the gradients just in case they blow up\n",
    "    clip_gradients()\n",
    "        \n",
    "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample the next character\n",
    "Used to see what the model is generating at some random sample point in the ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    \n",
    "    # one hot vector for the seed\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "\n",
    "    # obtain current c state and hidden state\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "    \n",
    "    # running container for the generated characters\n",
    "    indexes = []\n",
    "    \n",
    "    # run model for sentence_length number of ticks\n",
    "    for t in range(sentence_length):\n",
    "        \n",
    "        # perform forward pass ... note that we only care about th enew C state and hidden state as well as the output\n",
    "        # probabilities because we are not performing backprop\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        \n",
    "        # select a random with some probability associated with values\n",
    "        # np.random.choice(allPossibileOutcomes, probabilityOfTheOutcomes)\n",
    "        # choose a number in the vocab based on the probabilty distribution found in previous step\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        \n",
    "        # one-hot encode this in a vector\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        \n",
    "        # append running vector outputs\n",
    "        indexes.append(idx)\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the graph and display a sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(inputs, h_prev, C_prev, numChar):\n",
    "    #initialized later\n",
    "    global plot_iter, plot_loss\n",
    "    global smooth_loss\n",
    "    \n",
    "    # Get predictions for numOfCharToGenerate letters with current model\n",
    "\n",
    "    sample_idx = sample(h_prev, C_prev, inputs[0], numChar)\n",
    "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "\n",
    "    # Clear and plot\n",
    "    plt.plot(plot_iter, plot_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "    #Print prediction and loss\n",
    "    print(\"----\\n %s \\n----\" % (txt, ))\n",
    "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update parameters\n",
    "\n",
    "We will use adam descibed below.  \n",
    "\n",
    "![AdaGradImplementation](https://i.imgur.com/p9IvCME.png)\n",
    "\n",
    "Here eps and learning_rate is a hyper parameter and dx is the current gradient for a particular weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_paramters(params = parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d # Calculate sum of gradients\n",
    "        #print(learning_rate * dparam)\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ng wnr\n",
      "ene  fot ohrwtsatvad oo ine  sk oorn\n",
      "I'lellew ol titsingwns\n",
      "Iv'e lverthing nrwye\n",
      "wng ing I'w  \n",
      "----\n",
      "iter 1800, loss 39.941446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-de6951684551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# perform back and forwad pass throught through the LSTM with T-steps number of ticks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_h_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_C_prev\u001b[0m \u001b[1;33m=\u001b[0m         \u001b[0mforward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_h_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_C_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0msmooth_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmooth_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.999\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-c9d0c13f8842>\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(inputs, targets, h_prev, C_prev)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mg_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         v_s[t], y_s[t]) = \\\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Loss for this tick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-760b45fc9610>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(x, h_prev, C_prev, p)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# calculate LSTM gates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Reset\n",
    "    \n",
    "    # if the current pointer is outisde the number data points we have +  the step size or this is the first run of the loop\n",
    "    # initialize the hidden state and c state to zero and make the pointer point to the first character in our\n",
    "    # dataset\n",
    "    if pointer + T_steps >= len(data) or iteration == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "\n",
    "    # obtain the T_steps number of character of the input and target values\n",
    "    inputs = ([char_to_idx[ch] \n",
    "               for ch in data[pointer: pointer + T_steps]])\n",
    "    targets = ([char_to_idx[ch] \n",
    "                for ch in data[pointer + 1: pointer + T_steps + 1]])\n",
    "    \n",
    "    # perform back and forwad pass throught through the LSTM with T-steps number of ticks\n",
    "    loss, g_h_prev, g_C_prev = \\\n",
    "        forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "    # Print every hundred steps\n",
    "    if iteration % numOfIterToShowProgress == 0:\n",
    "        update_status(inputs, g_h_prev, g_C_prev, numOfCharToGenerate)\n",
    "    \n",
    "    # update the parameters\n",
    "    update_paramters()\n",
    "\n",
    "    # for visulaization purposes\n",
    "    plot_iter = np.append(plot_iter, [iteration])\n",
    "    plot_loss = np.append(plot_loss, [loss])\n",
    "    \n",
    "    # increment the datapointer to point to the next T-step as well as the iteration count\n",
    "    pointer += T_steps\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
